{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPyR Tools - Baseline Correction Tutorial\n",
    "\n",
    "This notebook demonstrates advanced baseline correction techniques for EPR spectra using EPyR Tools.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Understanding baseline issues in EPR spectra\n",
    "- Polynomial baseline correction (constant, linear, quadratic)\n",
    "- Advanced correction with signal exclusion regions\n",
    "- Comparing different correction methods\n",
    "- Best practices for baseline correction\n",
    "\n",
    "## Background\n",
    "\n",
    "Baseline drift is a common issue in EPR spectroscopy caused by:\n",
    "- Temperature changes during measurement\n",
    "- Instrumental drift\n",
    "- Sample heating effects\n",
    "- Microwave frequency instability\n",
    "\n",
    "Proper baseline correction is essential for:\n",
    "- Accurate peak integration\n",
    "- Reliable quantitative analysis\n",
    "- Spectral comparison and subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add EPyR Tools to path\n",
    "epyr_root = Path().resolve().parent.parent\n",
    "if str(epyr_root) not in sys.path:\n",
    "    sys.path.insert(0, str(epyr_root))\n",
    "\n",
    "import epyr.eprload as eprload\n",
    "from epyr.baseline import baseline_polynomial, baseline_exponential\n",
    "from epyr.baseline._utils import find_baseline_regions\n",
    "\n",
    "print(\"EPyR Tools baseline correction module loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Sample Data\n",
    "\n",
    "Let's start by loading EPR data that shows baseline issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load real EPR data first\n",
    "data_dir = Path(\"../data\")\n",
    "sample_file = None\n",
    "\n",
    "# Look for sample files\n",
    "for file_path in (data_dir / \"BES3T\").glob(\"*.dsc\"):\n",
    "    sample_file = file_path\n",
    "    break\n",
    "\n",
    "if not sample_file:\n",
    "    for file_path in (data_dir / \"ESP\").glob(\"*.par\"):\n",
    "        sample_file = file_path\n",
    "        break\n",
    "\n",
    "if sample_file:\n",
    "    print(f\"Loading real EPR data: {sample_file.name}\")\n",
    "    x, y, params, filepath = eprload.eprload(str(sample_file), plot_if_possible=False)\n",
    "    \n",
    "    if x is None or y is None:\n",
    "        print(\"Failed to load real data. Using synthetic data instead.\")\n",
    "        sample_file = None\n",
    "\n",
    "# Create synthetic data with realistic baseline issues\n",
    "if sample_file is None:\n",
    "    print(\"Creating synthetic EPR data with baseline drift...\")\n",
    "    \n",
    "    # Generate field axis\n",
    "    x = np.linspace(3200, 3400, 1000)\n",
    "    \n",
    "    # Create EPR signal (nitroxide radical with hyperfine splitting)\n",
    "    centers = [3320, 3350, 3380]  # A_N = 30 G\n",
    "    signal = np.zeros_like(x)\n",
    "    \n",
    "    for i, center in enumerate(centers):\n",
    "        # Slightly different intensities for realism\n",
    "        intensity = [80, 100, 75][i]  \n",
    "        width = 8  # Gaussian linewidth\n",
    "        signal += intensity * np.exp(-((x - center)**2) / (2 * width**2))\n",
    "    \n",
    "    # Add realistic baseline issues\n",
    "    baseline_drift = (\n",
    "        0.002 * (x - 3300)**2 +      # Quadratic drift (common)\n",
    "        -0.15 * (x - 3300) +         # Linear drift  \n",
    "        20 +                         # Constant offset\n",
    "        5 * np.sin((x - 3200) * 0.02) # Sinusoidal modulation (rare but possible)\n",
    "    )\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.normal(0, 1.5, len(x))\n",
    "    \n",
    "    # Combine signal, baseline, and noise\n",
    "    y = signal + baseline_drift + noise\n",
    "    \n",
    "    # Store true values for comparison\n",
    "    y_true_signal = signal\n",
    "    y_true_baseline = baseline_drift\n",
    "    \n",
    "    print(f\"Created synthetic spectrum with {len(x)} points\")\n",
    "    print(f\"Signal peak-to-peak: {np.ptp(signal):.1f}\")\n",
    "    print(f\"Baseline drift: {np.ptp(baseline_drift):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original data\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x, y, 'b-', linewidth=1.5, label='Raw spectrum (with baseline)')\n",
    "\n",
    "# If synthetic, show the true components\n",
    "if sample_file is None:\n",
    "    plt.plot(x, y_true_signal, 'g:', linewidth=2, label='True EPR signal')\n",
    "    plt.plot(x, y_true_baseline, 'r--', linewidth=1.5, alpha=0.7, label='True baseline')\n",
    "\n",
    "plt.xlabel('Magnetic Field (G)')\n",
    "plt.ylabel('EPR Signal (a.u.)')\n",
    "plt.title('Original EPR Spectrum - Baseline Issues Visible')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Show first derivative for better peak visibility\n",
    "plt.subplot(2, 1, 2)\n",
    "dy_dx = np.gradient(y, x)\n",
    "plt.plot(x, dy_dx, 'b-', linewidth=1.5, label='First derivative')\n",
    "plt.xlabel('Magnetic Field (G)')\n",
    "plt.ylabel('dχ\"/dB (a.u.)')\n",
    "plt.title('First Derivative - Shows Peak Positions Despite Baseline')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nOriginal spectrum statistics:\")\n",
    "print(f\"Mean: {np.mean(y):.2f}\")\n",
    "print(f\"Std: {np.std(y):.2f}\")\n",
    "print(f\"Range: {np.min(y):.2f} to {np.max(y):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Polynomial Baseline Correction\n",
    "\n",
    "The most common approach is fitting a polynomial to the baseline regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different polynomial orders\n",
    "corrections = {}\n",
    "\n",
    "print(\"Applying polynomial baseline corrections...\")\n",
    "\n",
    "# Constant offset (0th order)\n",
    "y_const, baseline_const = baseline_polynomial(y, x_data=x, poly_order=0)\n",
    "corrections['Constant (0th order)'] = (y_const, baseline_const)\n",
    "print(f\"✓ Constant correction: offset = {baseline_const[0]:.2f}\")\n",
    "\n",
    "# Linear (1st order)\n",
    "y_linear, baseline_linear = baseline_polynomial(y, x_data=x, poly_order=1)\n",
    "corrections['Linear (1st order)'] = (y_linear, baseline_linear)\n",
    "slope = (baseline_linear[-1] - baseline_linear[0]) / (x[-1] - x[0])\n",
    "print(f\"✓ Linear correction: slope = {slope:.4f} a.u./G\")\n",
    "\n",
    "# Quadratic (2nd order)\n",
    "y_quad, baseline_quad = baseline_polynomial(y, x_data=x, poly_order=2)\n",
    "corrections['Quadratic (2nd order)'] = (y_quad, baseline_quad)\n",
    "print(f\"✓ Quadratic correction applied\")\n",
    "\n",
    "# Cubic (3rd order) - be careful with higher orders!\n",
    "y_cubic, baseline_cubic = baseline_polynomial(y, x_data=x, poly_order=3)\n",
    "corrections['Cubic (3rd order)'] = (y_cubic, baseline_cubic)\n",
    "print(f\"✓ Cubic correction applied\")\n",
    "\n",
    "print(f\"\\nApplied {len(corrections)} different correction methods.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "methods = list(corrections.keys())\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    ax = axes[i]\n",
    "    y_corr, baseline_fit = corrections[method]\n",
    "    \n",
    "    # Plot original and corrected spectra\n",
    "    ax.plot(x, y, 'lightgray', linewidth=1, alpha=0.7, label='Original')\n",
    "    ax.plot(x, baseline_fit, 'r--', linewidth=1.5, alpha=0.8, label='Fitted baseline')\n",
    "    ax.plot(x, y_corr, 'b-', linewidth=1.5, label='Corrected')\n",
    "    \n",
    "    # If synthetic data, show true baseline for comparison\n",
    "    if sample_file is None:\n",
    "        ax.plot(x, y_true_baseline, 'k:', linewidth=1, alpha=0.6, label='True baseline')\n",
    "    \n",
    "    ax.set_xlabel('Magnetic Field (G)')\n",
    "    ax.set_ylabel('EPR Signal (a.u.)')\n",
    "    ax.set_title(f'{method} Correction')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=9)\n",
    "    \n",
    "    # Calculate and display RMS of residuals\n",
    "    residuals = y - baseline_fit\n",
    "    rms = np.sqrt(np.mean(residuals**2))\n",
    "    ax.text(0.02, 0.98, f'RMS: {rms:.2f}', transform=ax.transAxes,\n",
    "            verticalalignment='top', fontsize=10,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.suptitle('Polynomial Baseline Correction Comparison', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate quality metrics\n",
    "print(\"\\nCorrection Quality Metrics:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"{'Method':<20} {'RMS':<8} {'Signal Std':<12} {'Mean':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for method, (y_corr, baseline_fit) in corrections.items():\n",
    "    residuals = y - baseline_fit\n",
    "    rms = np.sqrt(np.mean(residuals**2))\n",
    "    signal_std = np.std(y_corr)\n",
    "    signal_mean = np.mean(y_corr)\n",
    "    print(f\"{method:<20} {rms:<8.2f} {signal_std:<12.2f} {signal_mean:<10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Correction with Signal Exclusion\n",
    "\n",
    "When EPR signals are strong, they can bias the baseline fit. We can exclude signal regions from the baseline calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify signal regions automatically\n",
    "print(\"Identifying signal regions for exclusion...\")\n",
    "\n",
    "# Method 1: Based on signal strength\n",
    "signal_threshold = np.std(y) * 2  # Points above 2 sigma\n",
    "baseline_mean = np.mean(y)\n",
    "\n",
    "# Find regions where signal deviates significantly from mean\n",
    "signal_mask = np.abs(y - baseline_mean) > signal_threshold\n",
    "signal_indices = np.where(signal_mask)[0]\n",
    "\n",
    "print(f\"Found {len(signal_indices)} points above threshold ({signal_threshold:.2f})\")\n",
    "\n",
    "# Group consecutive points into regions\n",
    "if len(signal_indices) > 0:\n",
    "    # Find breaks in consecutive indices\n",
    "    breaks = np.where(np.diff(signal_indices) > 10)[0] + 1  # Gap > 10 points\n",
    "    region_starts = np.concatenate(([0], breaks))\n",
    "    region_ends = np.concatenate((breaks, [len(signal_indices)]))\n",
    "    \n",
    "    exclude_regions = []\n",
    "    field_width = (x.max() - x.min()) / len(x) * 20  # Buffer around signals\n",
    "    \n",
    "    for start, end in zip(region_starts, region_ends):\n",
    "        idx_start = signal_indices[start]\n",
    "        idx_end = signal_indices[end-1]\n",
    "        \n",
    "        field_start = max(x[idx_start] - field_width, x.min())\n",
    "        field_end = min(x[idx_end] + field_width, x.max())\n",
    "        \n",
    "        exclude_regions.append((field_start, field_end))\n",
    "    \n",
    "    print(f\"Created {len(exclude_regions)} exclusion regions:\")\n",
    "    for i, (start, end) in enumerate(exclude_regions):\n",
    "        print(f\"  Region {i+1}: {start:.1f} - {end:.1f} G ({end-start:.1f} G width)\")\n",
    "else:\n",
    "    exclude_regions = []\n",
    "    print(\"No significant signal regions found for exclusion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply baseline correction with exclusion regions\n",
    "if exclude_regions:\n",
    "    print(\"\\nApplying corrections with signal exclusion...\")\n",
    "    \n",
    "    # Compare with and without exclusion\n",
    "    corrections_excl = {}\n",
    "    \n",
    "    # Linear with exclusion\n",
    "    y_lin_excl, baseline_lin_excl = baseline_polynomial(\n",
    "        y, x_data=x, poly_order=1, exclude_regions=exclude_regions\n",
    "    )\n",
    "    corrections_excl['Linear + Exclusion'] = (y_lin_excl, baseline_lin_excl)\n",
    "    \n",
    "    # Quadratic with exclusion\n",
    "    y_quad_excl, baseline_quad_excl = baseline_polynomial(\n",
    "        y, x_data=x, poly_order=2, exclude_regions=exclude_regions\n",
    "    )\n",
    "    corrections_excl['Quadratic + Exclusion'] = (y_quad_excl, baseline_quad_excl)\n",
    "    \n",
    "    # Create comparison plot\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "    \n",
    "    # Original spectrum with exclusion regions highlighted\n",
    "    ax = axes[0]\n",
    "    ax.plot(x, y, 'b-', linewidth=1.5, label='Original spectrum')\n",
    "    ax.plot(x, baseline_quad_excl, 'r--', linewidth=2, label='Baseline (with exclusions)')\n",
    "    \n",
    "    # Highlight excluded regions\n",
    "    for i, (start, end) in enumerate(exclude_regions):\n",
    "        label = 'Excluded regions' if i == 0 else \"\"\n",
    "        ax.axvspan(start, end, alpha=0.3, color='red', label=label)\n",
    "    \n",
    "    ax.set_xlabel('Magnetic Field (G)')\n",
    "    ax.set_ylabel('EPR Signal (a.u.)')\n",
    "    ax.set_title('Baseline Fitting with Signal Exclusion')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Compare corrections with and without exclusion\n",
    "    ax = axes[1]\n",
    "    ax.plot(x, y_quad, 'g-', linewidth=1.5, alpha=0.7, label='Quadratic (no exclusion)')\n",
    "    ax.plot(x, y_quad_excl, 'b-', linewidth=1.5, label='Quadratic + exclusion')\n",
    "    \n",
    "    if sample_file is None:  # Show true signal for synthetic data\n",
    "        ax.plot(x, y_true_signal, 'k:', linewidth=2, alpha=0.8, label='True signal')\n",
    "    \n",
    "    ax.set_xlabel('Magnetic Field (G)')\n",
    "    ax.set_ylabel('EPR Signal (a.u.)')\n",
    "    ax.set_title('Corrected Spectra Comparison')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Show the difference\n",
    "    ax = axes[2]\n",
    "    difference = y_quad_excl - y_quad\n",
    "    ax.plot(x, difference, 'm-', linewidth=1.5, label='Difference (exclusion - standard)')\n",
    "    ax.axhline(y=0, color='k', linestyle=':', alpha=0.5)\n",
    "    ax.set_xlabel('Magnetic Field (G)')\n",
    "    ax.set_ylabel('Signal Difference (a.u.)')\n",
    "    ax.set_title('Effect of Signal Exclusion')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Quality comparison\n",
    "    print(\"\\nComparison of exclusion methods:\")\n",
    "    rms_standard = np.sqrt(np.mean((y - baseline_quad)**2))\n",
    "    rms_exclusion = np.sqrt(np.mean((y - baseline_quad_excl)**2))\n",
    "    \n",
    "    print(f\"Standard quadratic RMS: {rms_standard:.3f}\")\n",
    "    print(f\"With exclusion RMS: {rms_exclusion:.3f}\")\n",
    "    print(f\"Improvement: {((rms_standard - rms_exclusion)/rms_standard)*100:.1f}%\")\n",
    "    \n",
    "    if sample_file is None:\n",
    "        # Compare with true signal for synthetic data\n",
    "        mse_standard = np.mean((y_quad - y_true_signal)**2)\n",
    "        mse_exclusion = np.mean((y_quad_excl - y_true_signal)**2)\n",
    "        print(f\"\\nMSE vs true signal:\")\n",
    "        print(f\"Standard: {mse_standard:.3f}\")\n",
    "        print(f\"Exclusion: {mse_exclusion:.3f}\")\n",
    "        print(f\"True signal recovery improvement: {((mse_standard - mse_exclusion)/mse_standard)*100:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping exclusion demonstration (no clear signal regions detected).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Alternative Baseline Correction Methods\n",
    "\n",
    "EPyR Tools also supports other baseline correction approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try exponential baseline correction (useful for some EPR artifacts)\n",
    "print(\"Testing exponential baseline correction...\")\n",
    "\n",
    "try:\n",
    "    y_exp, baseline_exp = baseline_exponential(y, x_data=x)\n",
    "    \n",
    "    # Compare exponential vs polynomial\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Original spectrum\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(x, y, 'b-', linewidth=1.5, label='Original')\n",
    "    plt.plot(x, baseline_quad, 'r--', linewidth=1.5, alpha=0.8, label='Polynomial baseline')\n",
    "    plt.plot(x, baseline_exp, 'g--', linewidth=1.5, alpha=0.8, label='Exponential baseline')\n",
    "    \n",
    "    if sample_file is None:\n",
    "        plt.plot(x, y_true_baseline, 'k:', linewidth=2, alpha=0.6, label='True baseline')\n",
    "    \n",
    "    plt.xlabel('Magnetic Field (G)')\n",
    "    plt.ylabel('EPR Signal (a.u.)')\n",
    "    plt.title('Baseline Fitting Methods Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Corrected spectra\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(x, y_quad, 'r-', linewidth=1.5, label='Polynomial corrected')\n",
    "    plt.plot(x, y_exp, 'g-', linewidth=1.5, label='Exponential corrected')\n",
    "    \n",
    "    if sample_file is None:\n",
    "        plt.plot(x, y_true_signal, 'k:', linewidth=2, alpha=0.8, label='True signal')\n",
    "    \n",
    "    plt.xlabel('Magnetic Field (G)')\n",
    "    plt.ylabel('EPR Signal (a.u.)')\n",
    "    plt.title('Corrected Spectra')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Difference between methods\n",
    "    plt.subplot(3, 1, 3)\n",
    "    diff_methods = y_exp - y_quad\n",
    "    plt.plot(x, diff_methods, 'm-', linewidth=1.5, label='Exponential - Polynomial')\n",
    "    plt.axhline(y=0, color='k', linestyle=':', alpha=0.5)\n",
    "    plt.xlabel('Magnetic Field (G)')\n",
    "    plt.ylabel('Signal Difference (a.u.)')\n",
    "    plt.title('Difference Between Correction Methods')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Method comparison statistics\n",
    "    rms_poly = np.sqrt(np.mean((y - baseline_quad)**2))\n",
    "    rms_exp = np.sqrt(np.mean((y - baseline_exp)**2))\n",
    "    \n",
    "    print(f\"\\nMethod comparison:\")\n",
    "    print(f\"Polynomial RMS: {rms_poly:.3f}\")\n",
    "    print(f\"Exponential RMS: {rms_exp:.3f}\")\n",
    "    \n",
    "    if rms_exp < rms_poly:\n",
    "        print(f\"Exponential method is {((rms_poly - rms_exp)/rms_poly)*100:.1f}% better\")\n",
    "    else:\n",
    "        print(f\"Polynomial method is {((rms_exp - rms_poly)/rms_exp)*100:.1f}% better\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Exponential correction failed: {e}\")\n",
    "    print(\"This is normal for some data types - polynomial methods are more robust.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Best Practices and Guidelines\n",
    "\n",
    "Here are some practical tips for baseline correction in EPR spectroscopy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate best practices with interactive examples\n",
    "print(\"EPR Baseline Correction Best Practices\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. Choose appropriate polynomial order\n",
    "print(\"\\n1. Choosing Polynomial Order:\")\n",
    "orders = [0, 1, 2, 3, 4, 5]\n",
    "rms_values = []\n",
    "\n",
    "for order in orders:\n",
    "    try:\n",
    "        _, baseline_fit = baseline_polynomial(y, x_data=x, poly_order=order)\n",
    "        rms = np.sqrt(np.mean((y - baseline_fit)**2))\n",
    "        rms_values.append(rms)\n",
    "        print(f\"  Order {order}: RMS = {rms:.3f}\")\n",
    "    except:\n",
    "        rms_values.append(np.inf)\n",
    "        print(f\"  Order {order}: Failed (overfitting)\")\n",
    "\n",
    "optimal_order = orders[np.argmin(rms_values)]\n",
    "print(f\"  → Optimal order for this data: {optimal_order}\")\n",
    "\n",
    "# Plot RMS vs order\n",
    "plt.figure(figsize=(10, 6))\n",
    "valid_orders = [o for o, r in zip(orders, rms_values) if r != np.inf]\n",
    "valid_rms = [r for r in rms_values if r != np.inf]\n",
    "\n",
    "plt.plot(valid_orders, valid_rms, 'bo-', linewidth=2, markersize=8)\n",
    "plt.axvline(x=optimal_order, color='r', linestyle='--', alpha=0.7, label=f'Optimal: Order {optimal_order}')\n",
    "plt.xlabel('Polynomial Order')\n",
    "plt.ylabel('RMS of Residuals')\n",
    "plt.title('Baseline Correction Quality vs Polynomial Order')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n2. When to Use Exclusion Regions:\")\n",
    "signal_to_baseline = np.ptp(y_true_signal) / np.ptp(y_true_baseline) if sample_file is None else \"Unknown\"\n",
    "if isinstance(signal_to_baseline, (int, float)):\n",
    "    print(f\"  Signal-to-baseline ratio: {signal_to_baseline:.2f}\")\n",
    "    if signal_to_baseline > 0.1:\n",
    "        print(\"  → Recommendation: Use exclusion regions (strong signals can bias baseline)\")\n",
    "    else:\n",
    "        print(\"  → Recommendation: Standard correction sufficient (weak signals)\")\n",
    "else:\n",
    "    print(\"  → For real data: Use exclusion if EPR signals are > 10% of baseline drift\")\n",
    "\n",
    "print(\"\\n3. Quality Assessment:\")\n",
    "y_final = y_quad_excl if 'y_quad_excl' in locals() else y_quad\n",
    "baseline_final = baseline_quad_excl if 'baseline_quad_excl' in locals() else baseline_quad\n",
    "\n",
    "# Check for over-correction signs\n",
    "corrected_mean = np.mean(y_final)\n",
    "corrected_std = np.std(y_final)\n",
    "corrected_trend = np.polyfit(x, y_final, 1)[0]  # Remaining linear trend\n",
    "\n",
    "print(f\"  Corrected spectrum mean: {corrected_mean:.3f} (should be near zero)\")\n",
    "print(f\"  Remaining linear trend: {corrected_trend:.6f} (should be near zero)\")\n",
    "print(f\"  Signal-to-noise ratio: {np.ptp(y_final) / corrected_std:.1f}\")\n",
    "\n",
    "if abs(corrected_trend) < 0.001:\n",
    "    print(\"  ✓ Good correction: minimal remaining trend\")\n",
    "else:\n",
    "    print(\"  ⚠ Possible under-correction: linear trend remains\")\n",
    "\n",
    "if abs(corrected_mean) < corrected_std:\n",
    "    print(\"  ✓ Good correction: mean near zero\")\n",
    "else:\n",
    "    print(\"  ⚠ Possible over-correction: mean shifted from zero\")\n",
    "\n",
    "print(\"\\n4. Method Selection Guidelines:\")\n",
    "print(\"  • Constant (order 0): Simple DC offset removal\")\n",
    "print(\"  • Linear (order 1): Most common, handles typical drift\")\n",
    "print(\"  • Quadratic (order 2): For curved baselines, temperature effects\")\n",
    "print(\"  • Higher orders: Use with caution, risk of over-correction\")\n",
    "print(\"  • Exclusion regions: When signals are strong relative to baseline\")\n",
    "print(\"  • Exponential: For specific instrumental artifacts (rare)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the corrected spectrum for further analysis\n",
    "output_dir = Path(\"../data/processed\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Use the best correction method\n",
    "y_best = y_quad_excl if 'y_quad_excl' in locals() else y_quad\n",
    "baseline_best = baseline_quad_excl if 'baseline_quad_excl' in locals() else baseline_quad\n",
    "method_name = \"quadratic_with_exclusion\" if 'y_quad_excl' in locals() else \"quadratic\"\n",
    "\n",
    "# Save as CSV for easy import into other software\n",
    "output_file = output_dir / f\"baseline_corrected_{method_name}.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'field_gauss': x,\n",
    "    'original_intensity': y,\n",
    "    'fitted_baseline': baseline_best,\n",
    "    'corrected_intensity': y_best\n",
    "})\n",
    "\n",
    "# Add metadata as comments\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(f\"# EPR Baseline Correction Results\\n\")\n",
    "    f.write(f\"# Method: {method_name}\\n\")\n",
    "    f.write(f\"# RMS residual: {np.sqrt(np.mean((y - baseline_best)**2)):.4f}\\n\")\n",
    "    f.write(f\"# Corrected mean: {np.mean(y_best):.4f}\\n\")\n",
    "    f.write(f\"# Generated by: EPyR Tools Baseline Correction Tutorial\\n\")\n",
    "    f.write(f\"#\\n\")\n",
    "\n",
    "df.to_csv(output_file, mode='a', index=False)\n",
    "print(f\"\\nCorrected spectrum saved: {output_file}\")\n",
    "\n",
    "# Final summary plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x, y, 'lightgray', linewidth=1, alpha=0.8, label='Original')\n",
    "plt.plot(x, baseline_best, 'r--', linewidth=2, alpha=0.8, label='Fitted baseline')\n",
    "plt.plot(x, y_best, 'b-', linewidth=2, label=f'Corrected ({method_name})')\n",
    "\n",
    "if sample_file is None:\n",
    "    plt.plot(x, y_true_signal, 'g:', linewidth=2, alpha=0.8, label='True signal')\n",
    "\n",
    "plt.xlabel('Magnetic Field (G)')\n",
    "plt.ylabel('EPR Signal (a.u.)')\n",
    "plt.title('Final Baseline Correction Result')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# First derivative of corrected spectrum\n",
    "plt.subplot(2, 1, 2)\n",
    "dy_corrected = np.gradient(y_best, x)\n",
    "plt.plot(x, dy_corrected, 'b-', linewidth=1.5, label='Corrected derivative')\n",
    "plt.xlabel('Magnetic Field (G)')\n",
    "plt.ylabel('dχ\"/dB (a.u.)')\n",
    "plt.title('First Derivative of Corrected Spectrum')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Baseline correction tutorial completed successfully!\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"- Load {output_file} for quantitative analysis\")\n",
    "print(f\"- Try the Advanced Analysis tutorial for peak fitting\")\n",
    "print(f\"- Process multiple files with Batch Processing tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial covered:\n",
    "\n",
    "### Key Concepts\n",
    "- **Baseline issues**: Common in EPR due to instrumental drift and temperature effects\n",
    "- **Polynomial correction**: Most versatile approach with different orders for different drift patterns\n",
    "- **Signal exclusion**: Important when EPR signals are strong relative to baseline\n",
    "- **Method selection**: Based on data characteristics and correction quality\n",
    "\n",
    "### Best Practices\n",
    "1. **Start simple**: Try linear correction first\n",
    "2. **Assess quality**: Check RMS, remaining trends, and mean values\n",
    "3. **Use exclusion**: When signals > 10% of baseline drift\n",
    "4. **Avoid over-correction**: Higher polynomial orders can distort signals\n",
    "5. **Visual inspection**: Always plot results to verify correction quality\n",
    "\n",
    "### When to Use Each Method\n",
    "- **Constant (order 0)**: Simple DC offset, very stable measurements\n",
    "- **Linear (order 1)**: Most EPR measurements, gradual drift\n",
    "- **Quadratic (order 2)**: Temperature effects, longer measurements\n",
    "- **With exclusion**: Strong signals, quantitative analysis\n",
    "- **Exponential**: Specific instrumental artifacts (rare)\n",
    "\n",
    "### Next Tutorials\n",
    "- **03_Advanced_Analysis.ipynb**: Peak fitting, integration, g-factor calculations\n",
    "- **04_Batch_Processing.ipynb**: Process multiple EPR files efficiently\n",
    "\n",
    "The corrected spectrum is now ready for quantitative EPR analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
