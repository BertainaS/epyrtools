{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPyR Tools - Basic Data Loading\n",
    "\n",
    "This notebook demonstrates the basic functionality for loading EPR data from Bruker spectrometers using EPyR Tools.\n",
    "\n",
    "## What you'll learn:\n",
    "- Loading BES3T (.dsc/.dta) and ESP (.par/.spc) files\n",
    "- Handling 1D and 2D EPR data formats\n",
    "- Basic visualization of EPR spectra\n",
    "- Parameter extraction and interpretation\n",
    "- Working with both real and complex data\n",
    "\n",
    "**Compatible with EPyR Tools v0.1.2+**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add EPyR Tools to Python path\n",
    "current_dir = Path().resolve()\n",
    "epyr_root = current_dir.parent.parent  # Go up two levels from notebooks to project root\n",
    "\n",
    "if str(epyr_root) not in sys.path:\n",
    "    sys.path.insert(0, str(epyr_root))\n",
    "    \n",
    "print(f\"Looking for EPyR Tools in: {epyr_root}\")\n",
    "print(f\"EPyR package should be at: {epyr_root / 'epyr'}\")\n",
    "\n",
    "# Check if epyr directory exists\n",
    "epyr_package_dir = epyr_root / 'epyr'\n",
    "if epyr_package_dir.exists():\n",
    "    print(f\"✅ EPyR package directory found\")\n",
    "else:\n",
    "    print(f\"❌ EPyR package directory not found\")\n",
    "    print(f\"Please make sure you're running this notebook from examples/notebooks/\")\n",
    "\n",
    "# Import EPyR Tools\n",
    "try:\n",
    "    import epyr\n",
    "    print(f\"\\n✅ EPyR Tools loaded successfully!\")\n",
    "    print(f\"Version: {epyr.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"\\n❌ Failed to import EPyR Tools: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Make sure you're in the examples/notebooks/ directory\")\n",
    "    print(\"2. Try: pip install -e . (from project root)\")\n",
    "    print(\"3. Check that epyr/ directory exists in project root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find Available Data Files\n",
    "\n",
    "Let's look for EPR data files in our consolidated data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for sample data files in the consolidated data directory\n",
    "data_dir = Path(\"../data\")\n",
    "\n",
    "print(f\"Looking for data files in: {data_dir.resolve()}\")\n",
    "\n",
    "# Find all EPR files in the data directory\n",
    "bes3t_files = list(data_dir.glob(\"*.DSC\")) + list(data_dir.glob(\"*.dsc\"))\n",
    "esp_files = list(data_dir.glob(\"*.par\"))\n",
    "\n",
    "print(f\"\\nFound {len(bes3t_files)} BES3T files and {len(esp_files)} ESP files\")\n",
    "\n",
    "print(\"\\nAvailable files:\")\n",
    "all_files = [(f, \"BES3T\") for f in bes3t_files] + [(f, \"ESP\") for f in esp_files]\n",
    "\n",
    "for i, (file_path, file_type) in enumerate(all_files):\n",
    "    file_size = file_path.stat().st_size / 1024  # KB\n",
    "    print(f\"{i+1}. [{file_type}] {file_path.name} ({file_size:.1f} KB)\")\n",
    "    \n",
    "if not all_files:\n",
    "    print(\"❌ No EPR files found!\")\n",
    "    print(f\"Please add your .DSC/.DTA or .PAR/.SPC files to: {data_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Analyze Each File\n",
    "\n",
    "Now let's load each file and see what type of data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store loaded data for later use\n",
    "loaded_data = []\n",
    "\n",
    "print(\"EPyR Tools - Basic Data Loading Example\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for file_format, file_path in all_files:\n",
    "    print(f\"\\n🔄 Loading {file_format} file: {file_path.name}\")\n",
    "    \n",
    "    try:\n",
    "        # Load EPR data\n",
    "        x, y, params, filepath = epyr.eprload(str(file_path), plot_if_possible=False)\n",
    "        \n",
    "        if x is None or y is None:\n",
    "            print(f\"  ❌ Failed to load data from {file_path.name}\")\n",
    "            continue\n",
    "        \n",
    "        # Handle both 1D and 2D data\n",
    "        if isinstance(x, list) and len(x) > 1:\n",
    "            # 2D data: x is a list of axes\n",
    "            print(f\"  📊 Data type: 2D\")\n",
    "            print(f\"  📐 Data shape: {y.shape}\")\n",
    "            print(f\"  📏 Dimensions: {len(x)} axes\")\n",
    "            if hasattr(x[0], '__len__'):\n",
    "                print(f\"  🧲 Field range: {x[0].min():.1f} to {x[0].max():.1f} G\")\n",
    "            # Use magnitude for complex data\n",
    "            y_display = np.abs(y) if np.iscomplexobj(y) else y\n",
    "            print(f\"  📈 Signal range: {y_display.min():.2e} to {y_display.max():.2e}\")\n",
    "            print(f\"  🔢 Complex data: {'Yes' if np.iscomplexobj(y) else 'No'}\")\n",
    "        else:\n",
    "            # 1D data: x is a single array\n",
    "            x_array = x[0] if isinstance(x, list) else x\n",
    "            print(f\"  📊 Data type: 1D\")\n",
    "            print(f\"  📏 Data points: {len(x_array)}\")\n",
    "            print(f\"  🧲 Field range: {x_array.min():.1f} to {x_array.max():.1f} G\")\n",
    "            print(f\"  📈 Signal range: {y.min():.2e} to {y.max():.2e}\")\n",
    "            print(f\"  🔢 Complex data: {'Yes' if np.iscomplexobj(y) else 'No'}\")\n",
    "        \n",
    "        # Display key parameters\n",
    "        key_params = {\n",
    "            \"MWFQ\": \"Microwave Frequency (Hz)\",\n",
    "            \"MWPW\": \"Microwave Power (dB)\",\n",
    "            \"AVGS\": \"Number of Averages\",\n",
    "            \"HCF\": \"Center Field (G)\",\n",
    "            \"HSW\": \"Sweep Width (G)\",\n",
    "            \"MF\": \"Frequency (GHz)\",\n",
    "            \"MP\": \"Power\",\n",
    "            \"MA\": \"Modulation Amplitude (G)\",\n",
    "            \"RCT\": \"Time Constant (s)\"\n",
    "        }\n",
    "        \n",
    "        print(\"  📋 Key Parameters:\")\n",
    "        found_params = 0\n",
    "        for param, description in key_params.items():\n",
    "            if param in params:\n",
    "                value = params[param]\n",
    "                print(f\"    • {description}: {value}\")\n",
    "                found_params += 1\n",
    "        \n",
    "        if found_params == 0:\n",
    "            print(\"    • No standard parameters found\")\n",
    "        \n",
    "        # Store for plotting\n",
    "        loaded_data.append({\n",
    "            'file_path': file_path,\n",
    "            'file_format': file_format,\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'params': params,\n",
    "            'is_2d': isinstance(x, list) and len(x) > 1,\n",
    "            'is_complex': np.iscomplexobj(y)\n",
    "        })\n",
    "        \n",
    "        print(f\"  ✅ Successfully loaded!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error loading {file_path.name}: {e}\")\n",
    "\n",
    "print(f\"\\n📊 Summary: Successfully loaded {len(loaded_data)} out of {len(all_files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the Data\n",
    "\n",
    "Now let's create plots for each loaded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib for better plots\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"📈 Creating visualizations for loaded data...\\n\")\n",
    "\n",
    "for i, data in enumerate(loaded_data):\n",
    "    print(f\"Plotting {i+1}/{len(loaded_data)}: {data['file_path'].name}\")\n",
    "    \n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    params = data['params']\n",
    "    file_path = data['file_path']\n",
    "    file_format = data['file_format']\n",
    "    is_2d = data['is_2d']\n",
    "    is_complex = data['is_complex']\n",
    "    \n",
    "    # Create plot based on data type\n",
    "    if is_2d:\n",
    "        # 2D data plotting\n",
    "        y_plot = np.abs(y) if is_complex else y\n",
    "        \n",
    "        if len(y_plot.shape) == 2:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "            \n",
    "            # 2D color map\n",
    "            im = ax1.imshow(y_plot, aspect='auto', origin='lower', cmap='viridis')\n",
    "            ax1.set_xlabel('Field Points')\n",
    "            ax1.set_ylabel('Parameter Points')\n",
    "            ax1.set_title(f'2D EPR Data: {file_path.stem}')\n",
    "            plt.colorbar(im, ax=ax1, label='Signal (a.u.)')\n",
    "            \n",
    "            # Representative slices\n",
    "            n_slices = min(5, y_plot.shape[0])\n",
    "            colors = plt.cm.tab10(np.linspace(0, 1, n_slices))\n",
    "            \n",
    "            for j in range(n_slices):\n",
    "                idx = j * (y_plot.shape[0] // n_slices) if n_slices > 1 else 0\n",
    "                if hasattr(x[0], '__len__'):\n",
    "                    ax2.plot(x[0], y_plot[idx, :], color=colors[j], \n",
    "                            alpha=0.8, linewidth=1.5, label=f'Slice {idx+1}')\n",
    "                else:\n",
    "                    ax2.plot(y_plot[idx, :], color=colors[j], \n",
    "                            alpha=0.8, linewidth=1.5, label=f'Slice {idx+1}')\n",
    "            \n",
    "            ax2.set_xlabel('Field (G)' if hasattr(x[0], '__len__') else 'Points')\n",
    "            ax2.set_ylabel('EPR Signal (a.u.)')\n",
    "            ax2.set_title('Representative Spectra')\n",
    "            ax2.legend()\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add data info\n",
    "            info_text = f\"Format: {file_format}\\nShape: {y.shape}\\nComplex: {is_complex}\"\n",
    "            ax1.text(0.02, 0.98, info_text, transform=ax1.transAxes,\n",
    "                    verticalalignment='top', bbox=dict(boxstyle='round', \n",
    "                    facecolor='white', alpha=0.8))\n",
    "        else:\n",
    "            # Fallback for unexpected format\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(y_plot.flatten(), \"b-\", linewidth=1.5)\n",
    "            plt.xlabel(\"Data Points\")\n",
    "            plt.ylabel(\"EPR Signal (a.u.)\")\n",
    "            plt.title(f\"EPR Data: {file_path.stem} ({file_format} format)\")\n",
    "            plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        # 1D data plotting\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        x_array = x[0] if isinstance(x, list) else x\n",
    "        plt.plot(x_array, y, \"b-\", linewidth=1.5)\n",
    "        plt.xlabel(\"Magnetic Field (G)\")\n",
    "        plt.ylabel(\"EPR Signal (a.u.)\")\n",
    "        plt.title(f\"EPR Spectrum: {file_path.stem} ({file_format} format)\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add info box\n",
    "        info_text = f\"Points: {len(x_array)}\\nRange: {x_array.max()-x_array.min():.0f} G\\nFormat: {file_format}\"\n",
    "        plt.text(0.02, 0.98, info_text, transform=plt.gca().transAxes,\n",
    "                 verticalalignment='top', bbox=dict(boxstyle='round', \n",
    "                 facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Add frequency info if available\n",
    "    freq = params.get(\"MWFQ\", params.get(\"MF\", None))\n",
    "    if freq:\n",
    "        if isinstance(freq, str):\n",
    "            try:\n",
    "                freq_ghz = float(freq)\n",
    "            except:\n",
    "                freq_ghz = None\n",
    "        else:\n",
    "            freq_ghz = freq / 1e9 if freq > 1e6 else freq\n",
    "        \n",
    "        if freq_ghz is not None:\n",
    "            # Add to appropriate axis\n",
    "            current_ax = plt.gca()\n",
    "            if is_2d and len(y.shape) == 2:\n",
    "                # For 2D plots, add to the second subplot\n",
    "                current_ax = plt.subplot(1, 2, 2)\n",
    "            \n",
    "            current_ax.text(\n",
    "                0.98, 0.02, f\"Frequency: {freq_ghz:.3f} GHz\",\n",
    "                transform=current_ax.transAxes,\n",
    "                verticalalignment='bottom', horizontalalignment='right',\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"yellow\", alpha=0.8),\n",
    "            )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\n✅ All plots created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Analysis Examples\n",
    "\n",
    "Let's perform some basic analysis on the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📊 Basic EPR Data Analysis\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for i, data in enumerate(loaded_data):\n",
    "    print(f\"\\n🔍 Analysis of: {data['file_path'].name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    is_2d = data['is_2d']\n",
    "    is_complex = data['is_complex']\n",
    "    \n",
    "    if is_2d:\n",
    "        print(f\"  📐 Data type: 2D ({y.shape})\")\n",
    "        print(f\"  🔢 Complex: {'Yes' if is_complex else 'No'}\")\n",
    "        \n",
    "        # Use magnitude for analysis if complex\n",
    "        y_analysis = np.abs(y) if is_complex else y\n",
    "        \n",
    "        print(f\"  📈 Signal statistics:\")\n",
    "        print(f\"    • Mean: {np.mean(y_analysis):.2e}\")\n",
    "        print(f\"    • Std: {np.std(y_analysis):.2e}\")\n",
    "        print(f\"    • Min: {np.min(y_analysis):.2e}\")\n",
    "        print(f\"    • Max: {np.max(y_analysis):.2e}\")\n",
    "        print(f\"    • Peak-to-peak: {np.ptp(y_analysis):.2e}\")\n",
    "        \n",
    "        # Find strongest signal position\n",
    "        max_pos = np.unravel_index(np.argmax(np.abs(y_analysis)), y_analysis.shape)\n",
    "        print(f\"  🎯 Strongest signal at position: {max_pos}\")\n",
    "        \n",
    "        # Field information if available\n",
    "        if hasattr(x[0], '__len__'):\n",
    "            field_at_max = x[0][max_pos[1]] if max_pos[1] < len(x[0]) else \"N/A\"\n",
    "            print(f\"  🧲 Field at strongest signal: {field_at_max} G\")\n",
    "            print(f\"  📏 Field range: {x[0].min():.1f} - {x[0].max():.1f} G\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"  📐 Data type: 1D ({len(y)} points)\")\n",
    "        print(f\"  🔢 Complex: {'Yes' if is_complex else 'No'}\")\n",
    "        \n",
    "        x_array = x[0] if isinstance(x, list) else x\n",
    "        \n",
    "        print(f\"  📈 Signal statistics:\")\n",
    "        print(f\"    • Mean: {np.mean(y):.2e}\")\n",
    "        print(f\"    • Std: {np.std(y):.2e}\")\n",
    "        print(f\"    • Min: {np.min(y):.2e}\")\n",
    "        print(f\"    • Max: {np.max(y):.2e}\")\n",
    "        print(f\"    • Peak-to-peak: {np.ptp(y):.2e}\")\n",
    "        print(f\"    • SNR estimate: {np.ptp(y)/np.std(y):.1f}\")\n",
    "        \n",
    "        # Find peaks and troughs\n",
    "        max_idx = np.argmax(np.abs(y))\n",
    "        max_field = x_array[max_idx]\n",
    "        print(f\"  🎯 Strongest signal at: {max_field:.1f} G\")\n",
    "        print(f\"  🧲 Field range: {x_array.min():.1f} - {x_array.max():.1f} G\")\n",
    "        print(f\"  📏 Field resolution: {(x_array.max()-x_array.min())/(len(x_array)-1):.2f} G/point\")\n",
    "    \n",
    "    # Parameter summary\n",
    "    params = data['params']\n",
    "    print(f\"  📋 Available parameters: {len(params)} total\")\n",
    "    \n",
    "    # Show microwave frequency in GHz if available\n",
    "    freq = params.get(\"MWFQ\", params.get(\"MF\", None))\n",
    "    if freq:\n",
    "        if isinstance(freq, str):\n",
    "            try:\n",
    "                freq_val = float(freq)\n",
    "            except:\n",
    "                freq_val = None\n",
    "        else:\n",
    "            freq_val = freq\n",
    "        \n",
    "        if freq_val:\n",
    "            freq_ghz = freq_val / 1e9 if freq_val > 1e6 else freq_val\n",
    "            print(f\"  📡 Microwave frequency: {freq_ghz:.4f} GHz\")\n",
    "            \n",
    "            # Calculate approximate g-factor for strongest signal\n",
    "            if not is_2d and freq_ghz > 1:\n",
    "                # g = hν / (μB * B), where h = 6.626e-34, μB = 9.274e-24, ν in Hz, B in Tesla\n",
    "                h = 6.626e-34  # Planck constant\n",
    "                mu_b = 9.274e-24  # Bohr magneton\n",
    "                b_tesla = max_field * 1e-4  # Convert Gauss to Tesla\n",
    "                if b_tesla > 0:\n",
    "                    g_factor = (h * freq_ghz * 1e9) / (mu_b * b_tesla)\n",
    "                    print(f\"  🔬 Approximate g-factor at peak: {g_factor:.3f}\")\n",
    "\n",
    "print(f\"\\n✅ Analysis complete for all {len(loaded_data)} datasets!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Data for Further Analysis\n",
    "\n",
    "Let's show how to export the data for use in other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"💾 Exporting Data for External Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"../data/exported\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "exported_files = []\n",
    "\n",
    "for i, data in enumerate(loaded_data):\n",
    "    file_path = data['file_path']\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    params = data['params']\n",
    "    is_2d = data['is_2d']\n",
    "    is_complex = data['is_complex']\n",
    "    \n",
    "    base_name = file_path.stem\n",
    "    \n",
    "    print(f\"\\n📤 Exporting: {file_path.name}\")\n",
    "    \n",
    "    if is_2d:\n",
    "        # For 2D data, export a few representative slices\n",
    "        y_export = np.abs(y) if is_complex else y\n",
    "        \n",
    "        # Export first 3 spectra as separate CSV files\n",
    "        n_export = min(3, y_export.shape[0])\n",
    "        for j in range(n_export):\n",
    "            csv_file = output_dir / f\"{base_name}_slice_{j+1}.csv\"\n",
    "            \n",
    "            if hasattr(x[0], '__len__'):\n",
    "                df = pd.DataFrame({\n",
    "                    'Field_G': x[0],\n",
    "                    'Intensity': y_export[j, :]\n",
    "                })\n",
    "            else:\n",
    "                df = pd.DataFrame({\n",
    "                    'Index': range(len(y_export[j, :])),\n",
    "                    'Intensity': y_export[j, :]\n",
    "                })\n",
    "            \n",
    "            # Add metadata as comments\n",
    "            with open(csv_file, 'w') as f:\n",
    "                f.write(f\"# EPyR Tools Export - Slice {j+1} of {base_name}\\n\")\n",
    "                f.write(f\"# Original file: {file_path.name}\\n\")\n",
    "                f.write(f\"# Data type: 2D {'Complex' if is_complex else 'Real'}\\n\")\n",
    "                f.write(f\"# Full shape: {y.shape}\\n\")\n",
    "                f.write(f\"# Slice index: {j}\\n\")\n",
    "                \n",
    "                # Add key parameters\n",
    "                freq = params.get(\"MWFQ\", params.get(\"MF\", None))\n",
    "                if freq:\n",
    "                    f.write(f\"# Frequency: {freq}\\n\")\n",
    "                \n",
    "                f.write(f\"#\\n\")\n",
    "                df.to_csv(f, index=False)\n",
    "            \n",
    "            print(f\"  ✅ Slice {j+1} saved: {csv_file.name}\")\n",
    "            exported_files.append(csv_file)\n",
    "        \n",
    "        # Also save full 2D data as numpy\n",
    "        npz_file = output_dir / f\"{base_name}_full_2D.npz\"\n",
    "        np.savez(npz_file, \n",
    "                 x_axis=x[0] if hasattr(x[0], '__len__') else np.arange(y.shape[1]),\n",
    "                 y_axis=x[1] if len(x) > 1 and hasattr(x[1], '__len__') else np.arange(y.shape[0]),\n",
    "                 intensity=y,\n",
    "                 is_complex=is_complex,\n",
    "                 original_file=str(file_path))\n",
    "        print(f\"  ✅ Full 2D data saved: {npz_file.name}\")\n",
    "        exported_files.append(npz_file)\n",
    "        \n",
    "    else:\n",
    "        # For 1D data, export as simple CSV\n",
    "        x_array = x[0] if isinstance(x, list) else x\n",
    "        \n",
    "        csv_file = output_dir / f\"{base_name}_1D.csv\"\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'Field_G': x_array,\n",
    "            'Intensity': y\n",
    "        })\n",
    "        \n",
    "        # Add metadata as comments\n",
    "        with open(csv_file, 'w') as f:\n",
    "            f.write(f\"# EPyR Tools Export - 1D EPR Spectrum\\n\")\n",
    "            f.write(f\"# Original file: {file_path.name}\\n\")\n",
    "            f.write(f\"# Data points: {len(x_array)}\\n\")\n",
    "            f.write(f\"# Field range: {x_array.min():.1f} - {x_array.max():.1f} G\\n\")\n",
    "            \n",
    "            # Add key parameters\n",
    "            for param, value in params.items():\n",
    "                if param in ['MWFQ', 'MWPW', 'HCF', 'HSW', 'MF', 'MP']:\n",
    "                    f.write(f\"# {param}: {value}\\n\")\n",
    "            \n",
    "            f.write(f\"#\\n\")\n",
    "            df.to_csv(f, index=False)\n",
    "        \n",
    "        print(f\"  ✅ 1D data saved: {csv_file.name}\")\n",
    "        exported_files.append(csv_file)\n",
    "\n",
    "print(f\"\\n📁 All exports saved to: {output_dir.resolve()}\")\n",
    "print(f\"📋 Total files exported: {len(exported_files)}\")\n",
    "\n",
    "print(f\"\\n💡 Usage examples:\")\n",
    "print(f\"  Python: df = pd.read_csv('filename.csv', comment='#')\")\n",
    "print(f\"  R: data <- read.csv('filename.csv')\")\n",
    "print(f\"  Excel: File → Open → filename.csv\")\n",
    "print(f\"  Origin/Igor: Import CSV with field separation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "🎉 **Congratulations!** You've successfully completed the basic EPR data loading tutorial!\n",
    "\n",
    "### What we accomplished:\n",
    "\n",
    "✅ **Loaded EPR data** from both BES3T (.dsc/.dta) and ESP (.par/.spc) formats  \n",
    "✅ **Handled different data types** including 1D spectra and 2D datasets  \n",
    "✅ **Managed complex data** by taking magnitude for visualization  \n",
    "✅ **Extracted key parameters** like frequency, power, and field settings  \n",
    "✅ **Created professional visualizations** with proper axis labels and info boxes  \n",
    "✅ **Performed basic analysis** including SNR estimation and g-factor calculation  \n",
    "✅ **Exported data** in formats compatible with other analysis tools  \n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- **Baseline Correction**: Remove drift and artifacts from your spectra\n",
    "- **Advanced Analysis**: Peak fitting, integration, and quantitative analysis\n",
    "- **FAIR Data Conversion**: Convert to open formats for better accessibility\n",
    "- **Batch Processing**: Automate analysis of multiple files\n",
    "\n",
    "### Key Functions Learned:\n",
    "\n",
    "- `epyr.eprload()` - Main function for loading EPR data\n",
    "- Handling both 1D arrays and 2D lists of axes\n",
    "- Complex data visualization using `np.abs()`\n",
    "- Parameter extraction and interpretation\n",
    "\n",
    "### Need Help?\n",
    "\n",
    "- Check the other example notebooks for more advanced features\n",
    "- Look at the example scripts in `examples/scripts/`\n",
    "- Visit the project documentation for API reference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
