{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPyR Tools - Getting Started\n",
    "\n",
    "Welcome to EPyR Tools! This notebook will guide you through the basics of loading and visualizing EPR (Electron Paramagnetic Resonance) data from Bruker spectrometers.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Loading EPR data from BES3T (.dsc/.dta) and ESP (.par/.spc) formats\n",
    "- Understanding EPR measurement parameters\n",
    "- Basic data visualization\n",
    "- Converting data to open formats (CSV, JSON, HDF5)\n",
    "\n",
    "## Requirements\n",
    "\n",
    "Make sure you have EPyR Tools installed and sample data files in the `../data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add EPyR Tools to path if running from examples\n",
    "epyr_root = Path().resolve().parent.parent\n",
    "if str(epyr_root) not in sys.path:\n",
    "    sys.path.insert(0, str(epyr_root))\n",
    "\n",
    "import epyr.eprload as eprload\n",
    "import epyr.fair as fair\n",
    "from epyr.constants import CONSTANTS\n",
    "\n",
    "print(\"EPyR Tools loaded successfully!\")\n",
    "print(f\"Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading EPR Data\n",
    "\n",
    "EPyR Tools can automatically detect and load both BES3T and ESP format files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find available sample files\n",
    "data_dir = Path(\"../data\")\n",
    "bes3t_dir = data_dir / \"BES3T\"\n",
    "esp_dir = data_dir / \"ESP\"\n",
    "\n",
    "print(\"Looking for sample EPR files...\")\n",
    "\n",
    "# Check for BES3T files\n",
    "bes3t_files = list(bes3t_dir.glob(\"*.dsc\"))\n",
    "esp_files = list(esp_dir.glob(\"*.par\"))\n",
    "\n",
    "print(f\"Found {len(bes3t_files)} BES3T files and {len(esp_files)} ESP files\")\n",
    "\n",
    "if bes3t_files:\n",
    "    print(\"BES3T files:\")\n",
    "    for f in bes3t_files:\n",
    "        print(f\"  - {f.name}\")\n",
    "\n",
    "if esp_files:\n",
    "    print(\"ESP files:\")\n",
    "    for f in esp_files:\n",
    "        print(f\"  - {f.name}\")\n",
    "\n",
    "if not (bes3t_files or esp_files):\n",
    "    print(\"No sample files found. Please add your Bruker EPR data files to:\")\n",
    "    print(f\"  - {bes3t_dir} (for BES3T .dsc/.dta pairs)\")\n",
    "    print(f\"  - {esp_dir} (for ESP .par/.spc pairs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first available file (or create synthetic data)\n",
    "sample_file = None\n",
    "\n",
    "if bes3t_files:\n",
    "    sample_file = bes3t_files[0]\n",
    "    file_format = \"BES3T\"\n",
    "elif esp_files:\n",
    "    sample_file = esp_files[0]\n",
    "    file_format = \"ESP\"\n",
    "\n",
    "if sample_file:\n",
    "    print(f\"Loading {file_format} file: {sample_file.name}\")\n",
    "    \n",
    "    # Load the EPR data\n",
    "    x, y, params, filepath = eprload.eprload(str(sample_file), plot_if_possible=False)\n",
    "    \n",
    "    if x is not None and y is not None:\n",
    "        print(f\"Successfully loaded {len(x)} data points\")\n",
    "        print(f\"Field range: {x.min():.1f} to {x.max():.1f} G\")\n",
    "        print(f\"Signal range: {y.min():.2e} to {y.max():.2e}\")\n",
    "    else:\n",
    "        print(\"Failed to load data. Creating synthetic example...\")\n",
    "        sample_file = None\n",
    "\n",
    "# Create synthetic data if no real files available\n",
    "if sample_file is None:\n",
    "    print(\"Creating synthetic EPR data for demonstration...\")\n",
    "    \n",
    "    # Generate synthetic EPR spectrum\n",
    "    x = np.linspace(3200, 3400, 1000)\n",
    "    \n",
    "    # Create a nitroxide-like EPR signal (three lines)\n",
    "    centers = [3320, 3350, 3380]  # A_N ~ 30 G splitting\n",
    "    signal = np.zeros_like(x)\n",
    "    \n",
    "    for center in centers:\n",
    "        signal += 100 * np.exp(-((x - center)**2) / 25)\n",
    "    \n",
    "    # Add some baseline and noise\n",
    "    baseline = 0.001 * (x - 3300) + 10\n",
    "    noise = np.random.normal(0, 2, len(x))\n",
    "    y = signal + baseline + noise\n",
    "    \n",
    "    # Create mock parameters\n",
    "    params = {\n",
    "        'MWFQ': 9.4e9,  # 9.4 GHz\n",
    "        'HCF': 3350.0,  # Center field\n",
    "        'HSW': 200.0,   # Sweep width\n",
    "        'RES': 1000,    # Resolution\n",
    "        'AVGS': 10      # Averages\n",
    "    }\n",
    "    \n",
    "    file_format = \"Synthetic\"\n",
    "    print(f\"Created synthetic spectrum with {len(x)} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding EPR Parameters\n",
    "\n",
    "Let's examine the measurement parameters extracted from the EPR file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key EPR parameters\n",
    "print(\"EPR Measurement Parameters:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Parameter mapping for different file formats\n",
    "param_info = {\n",
    "    'MWFQ': ('Microwave Frequency', 'Hz'),\n",
    "    'MF': ('Microwave Frequency', 'GHz'),\n",
    "    'MWPW': ('Microwave Power', 'dB'),\n",
    "    'MP': ('Microwave Power', 'W'),\n",
    "    'HCF': ('Center Field', 'G'),\n",
    "    'HSW': ('Sweep Width', 'G'),\n",
    "    'RES': ('Resolution', 'points'),\n",
    "    'REY': ('Resolution Y', 'points'),\n",
    "    'AVGS': ('Number of Averages', ''),\n",
    "    'SPTP': ('Sweep Time', 's'),\n",
    "    'RCAG': ('Receiver Gain', 'dB'),\n",
    "    'MCTC': ('Time Constant', 's')\n",
    "}\n",
    "\n",
    "for param, value in params.items():\n",
    "    if param in param_info:\n",
    "        name, unit = param_info[param]\n",
    "        print(f\"{name:20s}: {value} {unit}\")\n",
    "    else:\n",
    "        print(f\"{param:20s}: {value}\")\n",
    "\n",
    "# Calculate some derived parameters\n",
    "freq_hz = params.get('MWFQ', params.get('MF', 9.4e9))\n",
    "if isinstance(freq_hz, str):\n",
    "    freq_hz = float(freq_hz)\n",
    "    \n",
    "freq_ghz = freq_hz / 1e9 if freq_hz > 1e6 else freq_hz\n",
    "\n",
    "print(\"\\nDerived Parameters:\")\n",
    "print(f\"Frequency: {freq_ghz:.4f} GHz\")\n",
    "print(f\"g-value at center: {CONSTANTS['h'] * freq_hz / (CONSTANTS['mu_B'] * params.get('HCF', 3350) * 1e-4):.4f}\")\n",
    "print(f\"Field resolution: {params.get('HSW', 200) / len(x):.3f} G/point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Data Visualization\n",
    "\n",
    "Let's create a professional EPR spectrum plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main spectrum plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Main spectrum\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x, y, 'b-', linewidth=1.5, label='EPR Spectrum')\n",
    "plt.xlabel('Magnetic Field (G)')\n",
    "plt.ylabel('EPR Signal (a.u.)')\n",
    "plt.title(f'EPR Spectrum ({file_format} format) - Frequency: {freq_ghz:.3f} GHz')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Add parameter box\n",
    "info_text = f'Center: {params.get(\"HCF\", \"N/A\")} G\\n'\n",
    "info_text += f'Width: {params.get(\"HSW\", \"N/A\")} G\\n'\n",
    "info_text += f'Power: {params.get(\"MWPW\", params.get(\"MP\", \"N/A\"))}'\n",
    "\n",
    "plt.text(0.02, 0.98, info_text, transform=plt.gca().transAxes, \n",
    "         verticalalignment='top', fontsize=10,\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Derivative (first derivative is common in EPR)\n",
    "plt.subplot(2, 1, 2)\n",
    "dy_dx = np.gradient(y, x)\n",
    "plt.plot(x, dy_dx, 'r-', linewidth=1.5, label='First Derivative')\n",
    "plt.xlabel('Magnetic Field (G)')\n",
    "plt.ylabel('dχ\"/dB (a.u.)')\n",
    "plt.title('First Derivative (Common EPR Display)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nSpectrum Statistics:\")\n",
    "print(f\"Mean signal: {np.mean(y):.3f}\")\n",
    "print(f\"Signal std: {np.std(y):.3f}\")\n",
    "print(f\"Peak-to-peak: {np.max(y) - np.min(y):.3f}\")\n",
    "print(f\"Signal-to-noise ratio: {(np.max(y) - np.min(y)) / np.std(y):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Converting to Open Data Formats\n",
    "\n",
    "EPyR Tools can convert proprietary Bruker formats to open, FAIR-compliant formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to different formats\n",
    "output_dir = Path(\"../data/processed\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "base_name = \"tutorial_example\" if sample_file is None else sample_file.stem\n",
    "\n",
    "print(\"Converting to open formats...\")\n",
    "\n",
    "# 1. CSV format - simple and universal\n",
    "csv_file = output_dir / f\"{base_name}.csv\"\n",
    "fair.to_csv(x, y, params, str(csv_file))\n",
    "print(f\"✓ CSV saved: {csv_file.name}\")\n",
    "\n",
    "# 2. JSON format - structured with metadata\n",
    "json_file = output_dir / f\"{base_name}.json\"\n",
    "fair.to_json(x, y, params, str(json_file))\n",
    "print(f\"✓ JSON saved: {json_file.name}\")\n",
    "\n",
    "# 3. HDF5 format - hierarchical and efficient\n",
    "try:\n",
    "    h5_file = output_dir / f\"{base_name}.h5\"\n",
    "    fair.to_hdf5(x, y, params, str(h5_file))\n",
    "    print(f\"✓ HDF5 saved: {h5_file.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ HDF5 export failed: {e}\")\n",
    "    print(\"  Install h5py: pip install h5py\")\n",
    "\n",
    "print(f\"\\nFiles saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate loading the converted data back\n",
    "print(\"Demonstrating data round-trip...\")\n",
    "\n",
    "# Load CSV back\n",
    "import pandas as pd\n",
    "\n",
    "if csv_file.exists():\n",
    "    # Skip comment lines and load data\n",
    "    df = pd.read_csv(csv_file, comment='#')\n",
    "    x_csv = df['field_gauss'].values\n",
    "    y_csv = df['intensity_au'].values\n",
    "    \n",
    "    print(f\"Loaded {len(x_csv)} points from CSV\")\n",
    "    print(f\"Data integrity check: {np.allclose(x, x_csv) and np.allclose(y, y_csv)}\")\n",
    "\n",
    "# Load JSON back\n",
    "import json\n",
    "\n",
    "if json_file.exists():\n",
    "    with open(json_file, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    x_json = np.array(json_data['data']['field_axis'])\n",
    "    y_json = np.array(json_data['data']['intensity'])\n",
    "    \n",
    "    print(f\"Loaded {len(x_json)} points from JSON\")\n",
    "    print(f\"Original filename: {json_data.get('original_file', 'N/A')}\")\n",
    "    print(f\"Microwave frequency: {json_data['measurement_parameters']['microwave_frequency']['value']:.2e} Hz\")\n",
    "\n",
    "print(\"\\n✓ Data conversion and loading successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Next Steps\n",
    "\n",
    "Congratulations! You've learned the basics of EPyR Tools. Here's what to explore next:\n",
    "\n",
    "### Other Tutorials:\n",
    "- **02_Baseline_Correction.ipynb** - Remove baseline drift and artifacts\n",
    "- **03_Advanced_Analysis.ipynb** - Peak fitting, integration, and quantitative analysis\n",
    "- **04_Batch_Processing.ipynb** - Process multiple files efficiently\n",
    "\n",
    "### Key Features to Explore:\n",
    "- Baseline correction algorithms (polynomial, exponential, manual)\n",
    "- Peak detection and fitting\n",
    "- g-factor calculations and field calibration\n",
    "- Integration and double integration for quantification\n",
    "- 2D spectrum handling (field-swept, time-resolved)\n",
    "- Batch processing workflows\n",
    "\n",
    "### Adding Your Data:\n",
    "1. Place BES3T files (.dsc/.dta pairs) in `examples/data/BES3T/`\n",
    "2. Place ESP files (.par/.spc pairs) in `examples/data/ESP/`\n",
    "3. Run this notebook again to see your real EPR data!\n",
    "\n",
    "### Getting Help:\n",
    "- Check the API documentation for detailed function descriptions\n",
    "- Browse example scripts in `examples/scripts/`\n",
    "- Visit the project repository for updates and issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
